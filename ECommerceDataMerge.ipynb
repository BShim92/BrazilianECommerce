{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "from pprint import pprint\n",
    "from scipy.stats import linregress\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113425, 34)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_status</th>\n",
       "      <th>order_time</th>\n",
       "      <th>order_approved_at</th>\n",
       "      <th>order_delivered_carrier_date</th>\n",
       "      <th>order_delivered_customer_date</th>\n",
       "      <th>order_estimated_delivery_date</th>\n",
       "      <th>order_item_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>...</th>\n",
       "      <th>geolocation_lat</th>\n",
       "      <th>geolocation_lng</th>\n",
       "      <th>date_time</th>\n",
       "      <th>city</th>\n",
       "      <th>citylon</th>\n",
       "      <th>citylat</th>\n",
       "      <th>YYYY</th>\n",
       "      <th>MM</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e481f51cbdc54678b7cc49136f2d6af7</td>\n",
       "      <td>9ef432eb6251297304e76186b10a928d</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-10-02 10:56:33</td>\n",
       "      <td>2017-10-02 11:07:15</td>\n",
       "      <td>2017-10-04 19:55:00</td>\n",
       "      <td>2017-10-10 21:25:13</td>\n",
       "      <td>2017-10-18 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87285b34884572647811a353c7ac498a</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.574809</td>\n",
       "      <td>-46.587471</td>\n",
       "      <td>2017-10-01 10:56:33</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>10/17</td>\n",
       "      <td>10/01/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53cdb2fc8bc7dce0b6741e2150273451</td>\n",
       "      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-07-24 20:41:37</td>\n",
       "      <td>2018-07-26 03:24:27</td>\n",
       "      <td>2018-07-26 14:31:00</td>\n",
       "      <td>2018-08-07 15:27:45</td>\n",
       "      <td>2018-08-13 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>595fac2a385ac33a80bd5114aec74eb8</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.169860</td>\n",
       "      <td>-44.988369</td>\n",
       "      <td>2018-07-23 20:41:37</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>07/18</td>\n",
       "      <td>07/23/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47770eb9100c2d0c44946d9cf07ec65d</td>\n",
       "      <td>41ce2a54c0b03bf3443c3d931a367089</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-08-08 08:38:49</td>\n",
       "      <td>2018-08-08 08:55:23</td>\n",
       "      <td>2018-08-08 13:50:00</td>\n",
       "      <td>2018-08-17 18:06:29</td>\n",
       "      <td>2018-09-04 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>aa4383b373c6aca5d8797843e5594415</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.746337</td>\n",
       "      <td>-48.514624</td>\n",
       "      <td>2018-08-07 08:38:49</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>08/18</td>\n",
       "      <td>08/07/18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>\n",
       "      <td>f88197465ea7920adcdbec7375364d82</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2017-11-18 19:28:06</td>\n",
       "      <td>2017-11-18 19:45:59</td>\n",
       "      <td>2017-11-22 13:39:59</td>\n",
       "      <td>2017-12-02 00:28:42</td>\n",
       "      <td>2017-12-15 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>d0b61bfb1de832b15ba9d266ca96e5b0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.767733</td>\n",
       "      <td>-35.275467</td>\n",
       "      <td>2017-11-17 19:28:06</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>11/17</td>\n",
       "      <td>11/17/17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>\n",
       "      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>\n",
       "      <td>delivered</td>\n",
       "      <td>2018-02-13 21:18:39</td>\n",
       "      <td>2018-02-13 22:20:29</td>\n",
       "      <td>2018-02-14 19:46:34</td>\n",
       "      <td>2018-02-16 18:17:02</td>\n",
       "      <td>2018-02-26 00:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65266b2da20d04dbe00c5c2d3bb7859e</td>\n",
       "      <td>...</td>\n",
       "      <td>-23.675037</td>\n",
       "      <td>-46.524784</td>\n",
       "      <td>2018-02-12 21:18:39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>02/18</td>\n",
       "      <td>02/12/18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                       customer_id  \\\n",
       "0  e481f51cbdc54678b7cc49136f2d6af7  9ef432eb6251297304e76186b10a928d   \n",
       "1  53cdb2fc8bc7dce0b6741e2150273451  b0830fb4747a6c6d20dea0b8c802d7ef   \n",
       "2  47770eb9100c2d0c44946d9cf07ec65d  41ce2a54c0b03bf3443c3d931a367089   \n",
       "3  949d5b44dbf5de918fe9c16f97b45f8a  f88197465ea7920adcdbec7375364d82   \n",
       "4  ad21c59c0840e6cb83a9ceb5573f8159  8ab97904e6daea8866dbdbc4fb7aad2c   \n",
       "\n",
       "  order_status           order_time    order_approved_at  \\\n",
       "0    delivered  2017-10-02 10:56:33  2017-10-02 11:07:15   \n",
       "1    delivered  2018-07-24 20:41:37  2018-07-26 03:24:27   \n",
       "2    delivered  2018-08-08 08:38:49  2018-08-08 08:55:23   \n",
       "3    delivered  2017-11-18 19:28:06  2017-11-18 19:45:59   \n",
       "4    delivered  2018-02-13 21:18:39  2018-02-13 22:20:29   \n",
       "\n",
       "  order_delivered_carrier_date order_delivered_customer_date  \\\n",
       "0          2017-10-04 19:55:00           2017-10-10 21:25:13   \n",
       "1          2018-07-26 14:31:00           2018-08-07 15:27:45   \n",
       "2          2018-08-08 13:50:00           2018-08-17 18:06:29   \n",
       "3          2017-11-22 13:39:59           2017-12-02 00:28:42   \n",
       "4          2018-02-14 19:46:34           2018-02-16 18:17:02   \n",
       "\n",
       "  order_estimated_delivery_date  order_item_id  \\\n",
       "0           2017-10-18 00:00:00            1.0   \n",
       "1           2018-08-13 00:00:00            1.0   \n",
       "2           2018-09-04 00:00:00            1.0   \n",
       "3           2017-12-15 00:00:00            1.0   \n",
       "4           2018-02-26 00:00:00            1.0   \n",
       "\n",
       "                         product_id    ...    geolocation_lat geolocation_lng  \\\n",
       "0  87285b34884572647811a353c7ac498a    ...         -23.574809      -46.587471   \n",
       "1  595fac2a385ac33a80bd5114aec74eb8    ...         -12.169860      -44.988369   \n",
       "2  aa4383b373c6aca5d8797843e5594415    ...         -16.746337      -48.514624   \n",
       "3  d0b61bfb1de832b15ba9d266ca96e5b0    ...          -5.767733      -35.275467   \n",
       "4  65266b2da20d04dbe00c5c2d3bb7859e    ...         -23.675037      -46.524784   \n",
       "\n",
       "            date_time  city citylon  citylat  YYYY  MM  month       day  \n",
       "0 2017-10-01 10:56:33                         2017  10  10/17  10/01/17  \n",
       "1 2018-07-23 20:41:37                         2018   7  07/18  07/23/18  \n",
       "2 2018-08-07 08:38:49                         2018   8  08/18  08/07/18  \n",
       "3 2017-11-17 19:28:06                         2017  11  11/17  11/17/17  \n",
       "4 2018-02-12 21:18:39                         2018   2  02/18  02/12/18  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileordprod = \"./data/brazilian-ecommerce/olist_order_items_dataset.csv\"\n",
    "fileordcusttime = \"./data/brazilian-ecommerce/olist_orders_dataset.csv\"\n",
    "fileprodcat = \"./data/brazilian-ecommerce/olist_products_dataset.csv\"\n",
    "fileprodtransl = \"./data/brazilian-ecommerce/product_category_name_translation.csv\"\n",
    "filecustzip = \"./data/brazilian-ecommerce/olist_customers_dataset.csv\"\n",
    "filezipcoord = \"./data/brazilian-ecommerce/olist_geolocation_dataset.csv\"\n",
    "\n",
    "# Read Purchasing File and store into Pandas data frame\n",
    "ordprod = pd.read_csv(fileordprod)#[['order_id', 'product_id', 'price']]\n",
    "ordcusttime= pd.read_csv(fileordcusttime)#[['order_id', 'customer_id', 'order_purchase_timestamp']]\n",
    "prodcat = pd.read_csv(fileprodcat)#[['product_id', 'product_category_name']]\n",
    "prodtransl = pd.read_csv(fileprodtransl)\n",
    "custzip = pd.read_csv(filecustzip)[['customer_id','customer_zip_code_prefix']]\n",
    "zipcoord = pd.read_csv(filezipcoord)[['geolocation_zip_code_prefix', 'geolocation_lat', 'geolocation_lng']]\n",
    "\n",
    "zipcoord = zipcoord.rename(columns={'geolocation_zip_code_prefix': 'customer_zip_code_prefix'}).drop_duplicates(subset = 'customer_zip_code_prefix')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mergedf = pd.merge(ordcusttime, ordprod, on = 'order_id',how= 'left')\n",
    "mergedf = pd.merge(mergedf, prodcat, on = 'product_id', how = 'left')\n",
    "mergedf = pd.merge(mergedf, prodtransl, on = 'product_category_name', how = 'left')\n",
    "mergedf = pd.merge(mergedf, custzip, on = 'customer_id', how = 'left')\n",
    "mergedf = pd.merge(mergedf, zipcoord, on = 'customer_zip_code_prefix' , how = 'left')\n",
    "\n",
    "renamecolumns = {\n",
    "    'order_purchase_timestamp': 'order_time',\n",
    "    'product_category_name_english': 'category'\n",
    "}\n",
    "mergedf = mergedf.rename(columns = renamecolumns)\n",
    "\n",
    "\n",
    "#minus one day\n",
    "mergedf[\"date_time\"]= pd.to_datetime(mergedf['order_time']) - timedelta(days=1)\n",
    "\n",
    "mergedf['city'] = ''\n",
    "mergedf['citylon'] = ''\n",
    "mergedf['citylat'] = ''\n",
    "\n",
    "#converted to MM/YY Format\n",
    "mergedf['YYYY'] = pd.DatetimeIndex(mergedf['date_time']).year\n",
    "mergedf['MM'] = pd.DatetimeIndex(mergedf['date_time']).month\n",
    "\n",
    "mergedf['month'] = pd.to_datetime(mergedf['date_time'])\n",
    "mergedf['day'] = mergedf['month'].dt.strftime('%m/%d/%y')\n",
    "mergedf['month'] = mergedf['month'].dt.strftime('%m/%y')\n",
    "print(mergedf.shape)\n",
    "mergedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weatherurl = 'http://api.openweathermap.org/data/2.5/weather?'\n",
    "# weatherapikey = 'b457821be7196c46ce037583b6f2feb4'\n",
    "# for index, row in mergedf.iterrows():\n",
    "#     latitude = mergedf.loc[mergedf.index[index],'geolocation_lat']\n",
    "#     longitude = mergedf.loc[mergedf.index[index],'geolocation_lng']\n",
    "    \n",
    "#     params = {\n",
    "#     'lon': longitude,\n",
    "#     'lat': latitude,\n",
    "#     'appid': weatherapikey\n",
    "#     }\n",
    "    \n",
    "#     cityresponse = requests.get(weatherurl, params = params).json()\n",
    "    \n",
    "#     mergedf.loc[index, 'city'] = cityresponse['name']\n",
    "    \n",
    "#     if index % 500 == 0:\n",
    "#         print(index, 'city')\n",
    "\n",
    "# weatherurl = 'http://api.openweathermap.org/data/2.5/weather?'\n",
    "# weatherapikey = 'b457821be7196c46ce037583b6f2feb4'\n",
    "# for index, row in mergedf.iterrows():\n",
    "#     city = mergedf.loc[mergedf.index[index],'city']\n",
    "    \n",
    "#     params = {\n",
    "#     'q': city,\n",
    "#     'appid': weatherapikey\n",
    "#     }\n",
    "    \n",
    "#     cityresponse = requests.get(weatherurl, params = params).json()\n",
    "#     mergedf.loc[index, 'citylon'] = cityresponse['coord']['lon']\n",
    "#     mergedf.loc[index, 'citylat'] = cityresponse['coord']['lat']\n",
    "#     if index % 500 == 0:\n",
    "#         print(index, 'citylon & citylat')\n",
    "    \n",
    "# mergedf.to_csv('MergeDF.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-64.08885053080984\n",
      "-36.6053744107061\n",
      "42.18400274298598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-36.60537441, -35.60537441, -34.60537441, -33.60537441,\n",
       "       -32.60537441, -31.60537441, -30.60537441, -29.60537441,\n",
       "       -28.60537441, -27.60537441, -26.60537441, -25.60537441,\n",
       "       -24.60537441, -23.60537441, -22.60537441, -21.60537441,\n",
       "       -20.60537441, -19.60537441, -18.60537441, -17.60537441,\n",
       "       -16.60537441, -15.60537441, -14.60537441, -13.60537441,\n",
       "       -12.60537441, -11.60537441, -10.60537441,  -9.60537441,\n",
       "        -8.60537441,  -7.60537441,  -6.60537441,  -5.60537441,\n",
       "        -4.60537441,  -3.60537441,  -2.60537441,  -1.60537441,\n",
       "        -0.60537441,   0.39462559,   1.39462559,   2.39462559,\n",
       "         3.39462559,   4.39462559,   5.39462559,   6.39462559,\n",
       "         7.39462559,   8.39462559,   9.39462559,  10.39462559,\n",
       "        11.39462559,  12.39462559,  13.39462559,  14.39462559,\n",
       "        15.39462559,  16.39462559,  17.39462559,  18.39462559,\n",
       "        19.39462559,  20.39462559,  21.39462559,  22.39462559,\n",
       "        23.39462559,  24.39462559,  25.39462559,  26.39462559,\n",
       "        27.39462559,  28.39462559,  29.39462559,  30.39462559,\n",
       "        31.39462559,  32.39462559,  33.39462559,  34.39462559,\n",
       "        35.39462559,  36.39462559,  37.39462559,  38.39462559,\n",
       "        39.39462559,  40.39462559,  41.39462559])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(min(mergedf['geolocation_lng']) - max(mergedf['geolocation_lng']))\n",
    "print(min(mergedf['geolocation_lat']))\n",
    "print(max(mergedf['geolocation_lat']))\n",
    "np.arange(min(mergedf['geolocation_lng']), max(mergedf['geolocation_lng']))\n",
    "np.arange(min(mergedf['geolocation_lat']), max(mergedf['geolocation_lat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "0 5\n",
      "0 6\n",
      "0 7\n",
      "0 8\n",
      "0 9\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "1 7\n",
      "1 8\n",
      "1 9\n",
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "2 3\n",
      "2 4\n",
      "2 5\n",
      "2 6\n",
      "2 7\n",
      "2 8\n",
      "2 9\n",
      "3 0\n",
      "3 1\n",
      "3 2\n",
      "3 3\n",
      "3 4\n",
      "3 5\n",
      "3 6\n",
      "3 7\n",
      "3 8\n",
      "3 9\n",
      "4 0\n",
      "4 1\n",
      "4 2\n",
      "4 3\n",
      "4 4\n",
      "4 5\n",
      "4 6\n",
      "4 7\n",
      "4 8\n",
      "4 9\n",
      "5 0\n",
      "5 1\n",
      "5 2\n",
      "5 3\n",
      "5 4\n",
      "5 5\n",
      "5 6\n",
      "5 7\n",
      "5 8\n",
      "5 9\n",
      "6 0\n",
      "6 1\n",
      "6 2\n",
      "6 3\n",
      "6 4\n",
      "6 5\n",
      "6 6\n",
      "6 7\n",
      "6 8\n",
      "6 9\n",
      "7 0\n",
      "7 1\n",
      "7 2\n",
      "7 3\n",
      "7 4\n",
      "7 5\n",
      "7 6\n",
      "7 7\n",
      "7 8\n",
      "7 9\n",
      "8 0\n",
      "8 1\n",
      "8 2\n",
      "8 3\n",
      "8 4\n",
      "8 5\n",
      "8 6\n",
      "8 7\n",
      "8 8\n",
      "8 9\n",
      "9 0\n",
      "9 1\n",
      "9 2\n",
      "9 3\n",
      "9 4\n",
      "9 5\n",
      "9 6\n",
      "9 7\n",
      "9 8\n",
      "9 9\n"
     ]
    }
   ],
   "source": [
    "stepsize = 1\n",
    "for x in range(0, 10, stepsize):\n",
    "    for y in range(0, 10, stepsize):\n",
    "        print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "range?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlBOV = \"https://www.quandl.com/api/v3/datasets/BCB/7.json?api_key=2vRuu5GNchksqBdcAHzc\"\n",
    "responseBOV = requests.get(urlBOV).json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 10\n",
    "\n",
    "BOV_df = pd.DataFrame(responseBOV['dataset']['data'])\n",
    "\n",
    "BOV_df = BOV_df.rename(index=str, columns={0: \"day\", 1: \"BOV\"})\n",
    "\n",
    "BOV_df['day'] = pd.to_datetime(BOV_df['day'])\n",
    "BOV_df['day'] = BOV_df['day'].dt.strftime('%m/%d/%y')\n",
    "BOV_df['BOV'] = pd.to_numeric(BOV_df['BOV'])\n",
    "BOV_df = BOV_df.sort_values(by = 'day', ascending = True)\n",
    "BOV_df['BOVdiff'] = BOV_df['BOV'].diff(periods = days)\n",
    "BOV_df['BOVma'] = BOV_df['BOV'].rolling(window = days).mean()\n",
    "BOV_df.head(20)\n",
    "\n",
    "metriclist = ['BOV', 'BOVdiff', 'BOVma']\n",
    "mergedf = pd.merge(mergedf, BOV_df, on = 'day', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mergedf['day'] = pd.to_datetime(mergedf['day']) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mergedf['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# red = fashion/clothing\n",
    "    # 'perfumery', 'watches_gifts','fashion_underwear_beach','fashion_bags_accessories','fashion_shoes','fashion_male_clothing','fashion_sport','fashio_female_clothing','fashion_childrens_clothes'\n",
    "# orange = home/furniture\n",
    "    # 'housewares','furniture_decor','office_furniture','bed_bath_table','home_confort','furniture_bedroom','kitchen_dining_laundry_garden_furniture','home_comfort_2','furniture_mattress_and_upholstery'\n",
    "# yellow = construction/tools\n",
    "    # 'garden_tools','construction_tools_construction','construction_tools_lights','construction_tools_garden','construction_tools_safety','home_construction','construction_tools_tools'\n",
    "# purple = electronics\n",
    "    # 'computers_accessories','telephony','electionics','cds_dvds_musicals','consoles_games','audio','tablets_printing_image','computers','dvds_blu_ray','music'\n",
    "# green = food and drink\n",
    "    # 'food','drinks','food_drink','la_cuisine'\n",
    "# cyan = books\n",
    "    # 'books_general_interest','books_imported','books_technical'\n",
    "# gray = appliances\n",
    "    # 'air_conditioning','small_appliances','home_appliances','home_appliances_2','small_appliances_home_oven_and_coffee'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_categories = {'fashion_clothing': ['perfumery', 'luggage_accessories','watches_gifts','fashion_underwear_beach','fashion_bags_accessories','fashion_shoes','fashion_male_clothing','fashion_sport','fashio_female_clothing','fashion_childrens_clothes'],\n",
    "                  'home_furniture': ['housewares','art','arts_and_craftmanship','furniture_decor','office_furniture','bed_bath_table','home_confort','furniture_bedroom','kitchen_dining_laundry_garden_furniture','home_comfort_2','furniture_mattress_and_upholstery'],\n",
    "                  'construction_tools': ['garden_tools','construction_tools_construction','construction_tools_lights','construction_tools_garden','construction_tools_safety','home_construction','construction_tools_tools'],\n",
    "                  'electronics': ['computers_accessories','telephony','electionics','cds_dvds_musicals','consoles_games','audio','tablets_printing_image','computers','dvds_blu_ray','music'],\n",
    "                  'food_drink': ['food','drinks','food_drink','la_cuisine'],\n",
    "                  'books': ['books_general_interest','books_imported','books_technical'],\n",
    "                  'appliances': ['air_conditioning','small_appliances','home_appliances','home_appliances_2','small_appliances_home_oven_and_coffee'],\n",
    "                    'auto': ['auto'],\n",
    "                    'industry':['agro_industry_and_commerce','industry_commerce_and_business'],\n",
    "                    'other':['pet_shop','stationary','toys','baby','cool_stuff','sports_leisure','diapers_and_hygeine','signaling_and_security','party_supplies','cine_photo','market_place','musical_instruments','christmas_supplies']}\n",
    "                    \n",
    "new_dict = {}\n",
    "for key,valuelist in new_categories.items():\n",
    "    for v in valuelist:\n",
    "        new_dict[v] = key\n",
    "print(new_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedf['category'] = mergedf.category.replace(new_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rid of black friday\n",
    "mergedf = mergedf.loc[mergedf['day'] != '11/24/17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#commented out because it lags when rerunning all \n",
    "\n",
    "#save to excel file \n",
    "\n",
    "# writer = ExcelWriter('output.xlsx')\n",
    "# mergedf.to_excel(writer,'Sheet1',index=False)\n",
    "# writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_furniture = mergedf['price'][mergedf['category']=='home_furniture'].sum()\n",
    "fashion_clothing = mergedf['price'][mergedf['category']=='fashion_clothing'].sum()\n",
    "construction_tools = mergedf['price'][mergedf['category']=='construction_tools'].sum()\n",
    "electronics = mergedf['price'][mergedf['category']=='electronics'].sum()\n",
    "food_drink = mergedf['price'][mergedf['category']=='food_drink'].sum()\n",
    "books = mergedf['price'][mergedf['category']=='books'].sum()\n",
    "appliances = mergedf['price'][mergedf['category']=='appliances'].sum()\n",
    "#data['duration'][data['item'] == 'call'].sum()\n",
    "\n",
    "total_spend = home_furniture + fashion_clothing + construction_tools + electronics + food_drink + books + appliances\n",
    "\n",
    "category_spend = {home_furniture:'home_furniture',\n",
    "                        fashion_clothing:'fashion_clothing',\n",
    "                        construction_tools:'construction_tools',\n",
    "                        electronics:'electronics',\n",
    "                        food_drink:'food_drink',\n",
    "                        books:'books',\n",
    "                        appliances:'appliances'\n",
    "                       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedf['category'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(category_spend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_spend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = 'home/furniture', 'fashion/clothing', 'construction/tools', 'electronics','food and drink','books','appliances'\n",
    "sizes = [home_furniture, fashion_clothing, construction_tools, electronics, food_drink, books, appliances]\n",
    "explode = (0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "       shadow=True, startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.title('total spend')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Black Friday!\n",
    "mergedf.loc[mergedf['day'] == '11/24/17']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupdf = mergedf.groupby(['BOVdiff', 'category'])\n",
    "groupdf = groupdf.sum()\n",
    "groupdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#BY CATEGORIES\n",
    "for metric in metriclist:\n",
    "    for cat in new_categories.keys():\n",
    "        groupdf = mergedf.groupby([metric, 'category'])\n",
    "        groupdf = groupdf.sum()\n",
    "        #sum of prices\n",
    "        #groupdf = groupdf.sum()\n",
    "        groupdf.reset_index(inplace = True)\n",
    "        #why are there sum of prices at 0? no data from those dates?\n",
    "        groupdf = groupdf.loc[groupdf['price'] > 1]\n",
    "        #change categories\n",
    "        groupdf = groupdf.loc[groupdf['category'] == cat]\n",
    "\n",
    "        plt.scatter(groupdf[metric], groupdf['price'], color=[\"coral\"], edgecolor=\"black\", alpha = 0.75,marker=\"o\")\n",
    "        plt.ylim(0, max(groupdf['price']))\n",
    "        (slopeBOV, interceptBOV, rBOV, _, _) = linregress(groupdf[metric], groupdf['price'])\n",
    "        fitBOV = slopeBOV * groupdf[metric] + interceptBOV\n",
    "        plt.ylabel('Revenue per Day')\n",
    "        plt.xlabel(metric)\n",
    "        plt.title(f'Revenue vs {metric} for {cat}')\n",
    "        print(type(metric))\n",
    "        plt.plot(groupdf[metric], fitBOV)\n",
    "        print(f'R2 = {rBOV**2}')\n",
    "        plt.savefig('./Graphs/{metric}{cat}.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALL CATEGORIES\n",
    "for metric in metriclist:\n",
    "    groupdf = mergedf.groupby(metric)\n",
    "    groupdf = groupdf.sum()\n",
    "    groupdf.reset_index(inplace = True)\n",
    "    #why are there sum of prices at 0? no data from those dates?\n",
    "    groupdf = groupdf.loc[groupdf['price'] > 1]\n",
    "\n",
    "\n",
    "    plt.scatter(groupdf[metric], groupdf['price'])\n",
    "    plt.ylim(0, max(groupdf['price']))\n",
    "    (slopeBOV, interceptBOV, rBOV, _, _) = linregress(groupdf[metric], groupdf['price'])\n",
    "\n",
    "    fitBOV = slopeBOV * groupdf[metric] + interceptBOV\n",
    "    print(metric, rBOV**2)\n",
    "    plt.plot(groupdf[metric], fitBOV)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to see what the outlier point was\n",
    "#groupdf.sort_values('price', ascending= False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
